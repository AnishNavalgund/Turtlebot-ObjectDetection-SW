{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from yolov5.utils.general import increment_path, non_max_suppression\n",
    "from yolov5.utils.loss import ComputeLoss\n",
    "from yolov5.models.yolo import Model\n",
    "from yolov5.utils.torch_utils import select_device\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from yolov5.utils.datasets import LoadImagesAndLabels\n",
    "\n",
    "# Parameters\n",
    "INPUT_SIZE = 250  # Update to match your image size\n",
    "NUM_CLASSES = 3  # Update this to match your dataset\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 60\n",
    "LEARNING_RATE = 0.0001\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define paths\n",
    "train_data_path = '../yolo_data_v2/train/images'\n",
    "val_data_path = '../yolo_data_v2/val/images'\n",
    "weights_path = 'yolov5n.pt'  # Using YOLOv5 nano model\n",
    "\n",
    "# Create data.yaml for YOLO\n",
    "data_config = {\n",
    "    'train': train_data_path,\n",
    "    'val': val_data_path,\n",
    "    'nc': NUM_CLASSES,\n",
    "    'names': ['class0', 'class1', 'class2']  # Update class names as needed\n",
    "}\n",
    "\n",
    "with open('data.yaml', 'w') as f:\n",
    "    yaml.dump(data_config, f)\n",
    "\n",
    "# Load the YOLOv5 model\n",
    "model = Model(cfg='yolov5/models/yolov5n.yaml', nc=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(weights_path, map_location=DEVICE)['model'])\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = ComputeLoss(model)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = LoadImagesAndLabels(data_config['train'], img_size=INPUT_SIZE, batch_size=BATCH_SIZE, augment=True, rect=False)\n",
    "val_dataset = LoadImagesAndLabels(data_config['val'], img_size=INPUT_SIZE, batch_size=BATCH_SIZE, augment=False, rect=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for imgs, targets, paths, _ in train_loader:\n",
    "        imgs = imgs.to(DEVICE).float() / 255.0\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(imgs)\n",
    "        loss, _ = criterion(pred, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss/len(train_loader)}\")\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, targets, paths, shapes in val_loader:\n",
    "        imgs = imgs.to(DEVICE).float() / 255.0\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        pred = model(imgs)\n",
    "        loss, _ = criterion(pred, targets)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        # Collect predictions and true labels for evaluation\n",
    "        pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)\n",
    "        for p, t in zip(pred, targets):\n",
    "            if p is not None:\n",
    "                all_pred_labels.extend(p[:, -1].cpu().numpy())\n",
    "            all_true_labels.extend(t[:, -1].cpu().numpy())\n",
    "\n",
    "# Calculate mAP, precision, recall, F1 score\n",
    "# The below is a placeholder for actual mAP calculation\n",
    "precision, recall, f1 = 0.0, 0.0, 0.0  # Update with actual computation\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader)}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "\n",
    "# Visualization of predictions\n",
    "def visualize_predictions(images, predictions):\n",
    "    for img, pred in zip(images, predictions):\n",
    "        img = img.permute(1, 2, 0).cpu().numpy()\n",
    "        plt.imshow(img)\n",
    "        if pred is not None:\n",
    "            for box in pred:\n",
    "                x1, y1, x2, y2, conf, cls = box\n",
    "                plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=2))\n",
    "                plt.text(x1, y1 - 2, f'{int(cls)} {conf:.2f}', bbox=dict(facecolor='red', alpha=0.5), fontsize=12, color='white')\n",
    "        plt.show()\n",
    "\n",
    "# Run inference on validation set to visualize predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, targets, paths, shapes in val_loader:\n",
    "        imgs = imgs.to(DEVICE).float() / 255.0\n",
    "        pred = model(imgs)\n",
    "        pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)\n",
    "        visualize_predictions(imgs, pred)\n",
    "        break  # Visualize only the first batch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
