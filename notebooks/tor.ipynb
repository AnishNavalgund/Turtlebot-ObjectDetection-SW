{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# Parameters\n",
    "INPUT_SIZE = 250\n",
    "NUM_CLASSES = 3  # Update this to match your dataset\n",
    "MAX_OBJECTS = 10\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 60\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Create custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_dir, input_size, num_classes, max_objects, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.max_objects = max_objects\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "        self.label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "        assert len(self.image_files) == len(self.label_files), \"Number of images and labels must match\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        label_path = os.path.join(self.labels_dir, self.label_files[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        bboxes, class_ids = self.parse_label_file(label_path)\n",
    "\n",
    "        return image, bboxes, class_ids\n",
    "\n",
    "    def parse_label_file(self, label_path):\n",
    "        with open(label_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        bboxes = np.zeros((self.max_objects, 4), dtype=np.float32)\n",
    "        class_ids = np.zeros((self.max_objects, self.num_classes), dtype=np.float32)\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            if i >= self.max_objects:\n",
    "                break\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            bboxes[i] = [x_center - width / 2, y_center - height / 2, width, height]\n",
    "            class_ids[i, class_id] = 1.0\n",
    "\n",
    "        return bboxes, class_ids\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset('../yolo_data_v3/train/images', '../yolo_data_v3/train/labels', INPUT_SIZE, NUM_CLASSES, MAX_OBJECTS, transform)\n",
    "val_dataset = CustomDataset('../yolo_data_v3/val/images', '../yolo_data_v3/val/labels', INPUT_SIZE, NUM_CLASSES, MAX_OBJECTS, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class ObjectDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_anchors, input_size):\n",
    "        super(ObjectDetectionModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors = num_anchors\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512 * (input_size // 32) * (input_size // 32), 1024),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        \n",
    "        self.bbox_head = nn.Linear(256, num_anchors * 4)\n",
    "        self.class_head = nn.Linear(256, num_anchors * num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        bboxes = self.bbox_head(x).view(-1, self.num_anchors, 4)\n",
    "        class_logits = self.class_head(x).view(-1, self.num_anchors, self.num_classes)\n",
    "        return bboxes, class_logits\n",
    "\n",
    "    def inference(self, x, score_threshold=0.5, iou_threshold=0.5):\n",
    "        bboxes, class_logits = self.forward(x)\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        class_probs = torch.softmax(class_logits, dim=-1)\n",
    "        \n",
    "        # Filter out low score boxes\n",
    "        scores, labels = class_probs.max(dim=-1)\n",
    "        keep = scores > score_threshold\n",
    "        \n",
    "        bboxes = bboxes[keep]\n",
    "        scores = scores[keep]\n",
    "        labels = labels[keep]\n",
    "        \n",
    "        # Apply NMS\n",
    "        keep = nms(bboxes, scores, iou_threshold)\n",
    "        \n",
    "        return bboxes[keep], labels[keep], scores[keep]\n",
    "\n",
    "def nms(boxes, scores, iou_threshold=0.5):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    \n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    _, order = scores.sort(0, descending=True)\n",
    "    \n",
    "    keep = []\n",
    "    while order.numel() > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i.item())\n",
    "        \n",
    "        if order.numel() == 1:\n",
    "            break\n",
    "        \n",
    "        xx1 = torch.max(x1[i], x1[order[1:]])\n",
    "        yy1 = torch.max(y1[i], y1[order[1:]])\n",
    "        xx2 = torch.min(x2[i], x2[order[1:]])\n",
    "        yy2 = torch.min(y2[i], y2[order[1:]])\n",
    "        \n",
    "        w = (xx2 - xx1).clamp(min=0)\n",
    "        h = (yy2 - yy1).clamp(min=0)\n",
    "        inter = w * h\n",
    "        \n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        \n",
    "        order = order[1:][iou <= iou_threshold]\n",
    "    \n",
    "    return keep\n",
    "\n",
    "model = ObjectDetectionModel(NUM_CLASSES, MAX_OBJECTS, INPUT_SIZE)\n",
    "\n",
    "# Define loss functions\n",
    "def bbox_loss_fn(pred_bboxes, true_bboxes):\n",
    "    return nn.functional.mse_loss(pred_bboxes, true_bboxes)\n",
    "\n",
    "def class_loss_fn(pred_class_logits, true_class_ids):\n",
    "    return nn.functional.binary_cross_entropy_with_logits(pred_class_logits, true_class_ids)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Initialize lists to store loss and accuracy\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, true_bboxes, true_class_ids in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred_bboxes, pred_class_logits = model(images)\n",
    "        \n",
    "        bbox_loss = bbox_loss_fn(pred_bboxes, true_bboxes)\n",
    "        class_loss = class_loss_fn(pred_class_logits, true_class_ids)\n",
    "        \n",
    "        loss = bbox_loss + class_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted_train = torch.max(pred_class_logits, 2)\n",
    "        _, true_train = torch.max(true_class_ids, 2)\n",
    "        total_train += true_train.size(0) * true_train.size(1)\n",
    "        correct_train += (predicted_train == true_train).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(correct_train / total_train)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, true_bboxes, true_class_ids in val_loader:\n",
    "            pred_bboxes, pred_class_logits = model(images)\n",
    "            \n",
    "            bbox_loss = bbox_loss_fn(pred_bboxes, true_bboxes)\n",
    "            class_loss = class_loss_fn(pred_class_logits, true_class_ids)\n",
    "            \n",
    "            val_loss += bbox_loss.item() + class_loss.item()\n",
    "            \n",
    "            _, predicted_val = torch.max(pred_class_logits, 2)\n",
    "            _, true_val = torch.max(true_class_ids, 2)\n",
    "            total_val += true_val.size(0) * true_val.size(1)\n",
    "            correct_val += (predicted_val == true_val).sum().item()\n",
    "            \n",
    "            # Collect all true and predicted class labels for confusion matrix\n",
    "            true_class_ids_np = true_class_ids.cpu().numpy()\n",
    "            pred_class_logits_np = pred_class_logits.cpu().numpy()\n",
    "            all_true_labels.extend(np.argmax(true_class_ids_np, axis=2).flatten())\n",
    "            all_pred_labels.extend(np.argmax(pred_class_logits_np, axis=2).flatten())\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(correct_val / total_val)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='weighted', zero_division=1)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_pred_labels, labels=list(range(NUM_CLASSES)))\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=list(range(NUM_CLASSES)))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(EPOCHS), train_losses, label='Train Loss')\n",
    "plt.plot(range(EPOCHS), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(EPOCHS), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(EPOCHS), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Classification report for detailed metrics\n",
    "print(classification_report(all_true_labels, all_pred_labels, target_names=[f'Class {i}' for i in range(NUM_CLASSES)], zero_division=1))\n",
    "\n",
    "# Visualization function\n",
    "def visualize_predictions(images, pred_bboxes, pred_class_logits):\n",
    "    images = images.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    pred_bboxes = pred_bboxes.cpu().detach().numpy()\n",
    "    pred_class_logits = pred_class_logits.cpu().detach().numpy()\n",
    "    pred_class_ids = np.argmax(pred_class_logits, axis=-1)\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        plt.imshow(images[i])\n",
    "        for j in range(pred_bboxes.shape[1]):\n",
    "            bbox = pred_bboxes[i, j]\n",
    "            class_id = pred_class_ids[i, j]\n",
    "            confidence = np.max(pred_class_logits[i, j])\n",
    "            if confidence > 0.5:  # Only show high-confidence predictions\n",
    "                plt.gca().add_patch(plt.Rectangle(\n",
    "                    (bbox[0] * INPUT_SIZE, bbox[1] * INPUT_SIZE),\n",
    "                    bbox[2] * INPUT_SIZE,\n",
    "                    bbox[3] * INPUT_SIZE,\n",
    "                    fill=False,\n",
    "                    edgecolor='red',\n",
    "                    linewidth=2\n",
    "                ))\n",
    "                plt.text(\n",
    "                    bbox[0] * INPUT_SIZE,\n",
    "                    bbox[1] * INPUT_SIZE - 5,\n",
    "                    f'Class {class_id}, Conf: {confidence:.2f}',\n",
    "                    bbox=dict(facecolor='red', alpha=0.5),\n",
    "                    fontsize=12,\n",
    "                    color='white'\n",
    "                )\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, true_bboxes, true_class_ids in val_loader:\n",
    "        pred_bboxes, pred_class_logits = model(images)\n",
    "        visualize_predictions(images, pred_bboxes, pred_class_logits)\n",
    "        break  # Visualize only the first batch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
