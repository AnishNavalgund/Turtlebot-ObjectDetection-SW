{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support, classification_report\n",
    "from torchvision import models\n",
    "\n",
    "# Parameters\n",
    "INPUT_SIZE = 250\n",
    "NUM_CLASSES = 3  # Update this to match your dataset\n",
    "MAX_OBJECTS = 10\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 60\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Create custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_dir, input_size, num_classes, max_objects, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.max_objects = max_objects\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "        self.label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "        assert len(self.image_files) == len(self.label_files), \"Number of images and labels must match\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        label_path = os.path.join(self.labels_dir, self.label_files[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        bboxes, class_ids = self.parse_label_file(label_path)\n",
    "\n",
    "        return image, bboxes, class_ids\n",
    "\n",
    "    def parse_label_file(self, label_path):\n",
    "        with open(label_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        bboxes = np.zeros((self.max_objects, 4), dtype=np.float32)\n",
    "        class_ids = np.zeros((self.max_objects, self.num_classes), dtype=np.float32)\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            if i >= self.max_objects:\n",
    "                break\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            bboxes[i] = [x_center - width / 2, y_center - height / 2, width, height]\n",
    "            class_ids[i, class_id] = 1.0\n",
    "\n",
    "        return bboxes, class_ids\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset('../yolo_data_v2/train/images', '../yolo_data_v2/train/labels', INPUT_SIZE, NUM_CLASSES, MAX_OBJECTS, transform)\n",
    "val_dataset = CustomDataset('../yolo_data_v2/val/images', '../yolo_data_v2/val/labels', INPUT_SIZE, NUM_CLASSES, MAX_OBJECTS, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define SSD-based model\n",
    "class SSD(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SSD, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.base_net = models.vgg16(pretrained=True).features\n",
    "        \n",
    "        self.extras = nn.ModuleList([\n",
    "            nn.Conv2d(512, 256, kernel_size=1, stride=1),  # Adjust input channels to 512\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(512, 128, kernel_size=1, stride=1),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(256, 128, kernel_size=1, stride=1),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(256, 128, kernel_size=1, stride=1),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        ])\n",
    "        \n",
    "        # Number of default boxes (anchors) per feature map location\n",
    "        self.num_defaults = [4, 6, 6, 6, 4, 4]\n",
    "        \n",
    "        # Localization (bounding box) prediction layers\n",
    "        self.loc = nn.ModuleList([\n",
    "            nn.Conv2d(512, self.num_defaults[0] * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(512, self.num_defaults[1] * 4, kernel_size=3, padding=1),  # Adjust input channels to 512\n",
    "            nn.Conv2d(512, self.num_defaults[2] * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, self.num_defaults[3] * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, self.num_defaults[4] * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, self.num_defaults[5] * 4, kernel_size=3, padding=1)\n",
    "        ])\n",
    "        \n",
    "        # Confidence (class scores) prediction layers\n",
    "        self.conf = nn.ModuleList([\n",
    "            nn.Conv2d(512, self.num_defaults[0] * num_classes, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(512, self.num_defaults[1] * num_classes, kernel_size=3, padding=1),  # Adjust input channels to 512\n",
    "            nn.Conv2d(512, self.num_defaults[2] * num_classes, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, self.num_defaults[3] * num_classes, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, self.num_defaults[4] * num_classes, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, self.num_defaults[5] * num_classes, kernel_size=3, padding=1)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        locs = []\n",
    "        confs = []\n",
    "        \n",
    "        # Extract features from base network (VGG16)\n",
    "        for i in range(23):\n",
    "            x = self.base_net[i](x)\n",
    "        features.append(x)\n",
    "        \n",
    "        for i in range(23, len(self.base_net)):\n",
    "            x = self.base_net[i](x)\n",
    "        features.append(x)\n",
    "        \n",
    "        # Apply additional convolutional layers (extras)\n",
    "        for i, v in enumerate(self.extras):\n",
    "            x = v(x)\n",
    "            if i % 2 == 1:\n",
    "                features.append(x)\n",
    "        \n",
    "        # Predict bounding boxes and class scores\n",
    "        for (x, l, c) in zip(features, self.loc, self.conf):\n",
    "            locs.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            confs.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "        \n",
    "        locs = torch.cat([o.view(o.size(0), -1) for o in locs], 1)\n",
    "        confs = torch.cat([o.view(o.size(0), -1) for o in confs], 1)\n",
    "        \n",
    "        locs = locs.view(locs.size(0), -1, 4)\n",
    "        confs = confs.view(confs.size(0), -1, self.num_classes)\n",
    "        \n",
    "        return locs, confs\n",
    "\n",
    "# Define NMS function\n",
    "def nms(boxes, scores, iou_threshold=0.5):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    \n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    _, order = scores.sort(0, descending=True)\n",
    "    \n",
    "    keep = []\n",
    "    while order.numel() > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i.item())\n",
    "        \n",
    "        if order.numel() == 1:\n",
    "            break\n",
    "        \n",
    "        xx1 = torch.max(x1[i], x1[order[1:]])\n",
    "        yy1 = torch.max(y1[i], y1[order[1:]])\n",
    "        xx2 = torch.min(x2[i], x2[order[1:]])\n",
    "        yy2 = torch.min(y2[i], y2[order[1:]])\n",
    "        \n",
    "        w = (xx2 - xx1).clamp(min=0)\n",
    "        h = (yy2 - yy1).clamp(min=0)\n",
    "        inter = w * h\n",
    "        \n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        \n",
    "        order = order[1:][iou <= iou_threshold]\n",
    "    \n",
    "    return keep\n",
    "\n",
    "model = SSD(NUM_CLASSES)\n",
    "\n",
    "# Define loss functions\n",
    "def bbox_loss_fn(pred_bboxes, true_bboxes):\n",
    "    # Ensure true_bboxes have the same shape as pred_bboxes\n",
    "    pred_shape = pred_bboxes.shape\n",
    "    true_bboxes = true_bboxes.view(pred_shape)\n",
    "    return nn.functional.mse_loss(pred_bboxes, true_bboxes)\n",
    "\n",
    "def class_loss_fn(pred_class_logits, true_class_ids):\n",
    "    return nn.functional.binary_cross_entropy_with_logits(pred_class_logits, true_class_ids)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Initialize lists to store loss and accuracy\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, true_bboxes, true_class_ids in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred_bboxes, pred_class_logits = model(images)\n",
    "        \n",
    "        # Reshape true_bboxes to match pred_bboxes\n",
    "        true_bboxes = true_bboxes.view(pred_bboxes.shape)\n",
    "        \n",
    "        bbox_loss = bbox_loss_fn(pred_bboxes, true_bboxes)\n",
    "        class_loss = class_loss_fn(pred_class_logits, true_class_ids)\n",
    "        \n",
    "        loss = bbox_loss + class_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted_train = torch.max(pred_class_logits, 2)\n",
    "        _, true_train = torch.max(true_class_ids, 2)\n",
    "        total_train += true_train.size(0) * true_train.size(1)\n",
    "        correct_train += (predicted_train == true_train).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(correct_train / total_train)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, true_bboxes, true_class_ids in val_loader:\n",
    "            pred_bboxes, pred_class_logits = model(images)\n",
    "            \n",
    "            # Reshape true_bboxes to match pred_bboxes\n",
    "            true_bboxes = true_bboxes.view(pred_bboxes.shape)\n",
    "            \n",
    "            bbox_loss = bbox_loss_fn(pred_bboxes, true_bboxes)\n",
    "            class_loss = class_loss_fn(pred_class_logits, true_class_ids)\n",
    "            \n",
    "            val_loss += bbox_loss.item() + class_loss.item()\n",
    "            \n",
    "            _, predicted_val = torch.max(pred_class_logits, 2)\n",
    "            _, true_val = torch.max(true_class_ids, 2)\n",
    "            total_val += true_val.size(0) * true_val.size(1)\n",
    "            correct_val += (predicted_val == true_val).sum().item()\n",
    "            \n",
    "            # Collect all true and predicted class labels for confusion matrix\n",
    "            true_class_ids_np = true_class_ids.cpu().numpy()\n",
    "            pred_class_logits_np = pred_class_logits.cpu().numpy()\n",
    "            all_true_labels.extend(np.argmax(true_class_ids_np, axis=2).flatten())\n",
    "            all_pred_labels.extend(np.argmax(pred_class_logits_np, axis=2).flatten())\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(correct_val / total_val)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='weighted', zero_division=1)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_pred_labels, labels=list(range(NUM_CLASSES)))\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=list(range(NUM_CLASSES)))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(EPOCHS), train_losses, label='Train Loss')\n",
    "plt.plot(range(EPOCHS), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(EPOCHS), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(EPOCHS), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Classification report for detailed metrics\n",
    "print(classification_report(all_true_labels, all_pred_labels, target_names=[f'Class {i}' for i in range(NUM_CLASSES)], zero_division=1))\n",
    "\n",
    "# Visualization function\n",
    "def visualize_predictions(images, pred_bboxes, pred_class_logits):\n",
    "    images = images.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    pred_bboxes = pred_bboxes.cpu().detach().numpy()\n",
    "    pred_class_logits = pred_class_logits.cpu().detach().numpy()\n",
    "    pred_class_ids = np.argmax(pred_class_logits, axis=-1)\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        plt.imshow(images[i])\n",
    "        for j in range(pred_bboxes.shape[1]):\n",
    "            bbox = pred_bboxes[i, j]\n",
    "            class_id = pred_class_ids[i, j]\n",
    "            confidence = np.max(pred_class_logits[i, j])\n",
    "            if confidence > 0.5:  # Only show high-confidence predictions\n",
    "                plt.gca().add_patch(plt.Rectangle(\n",
    "                    (bbox[0] * INPUT_SIZE, bbox[1] * INPUT_SIZE),\n",
    "                    bbox[2] * INPUT_SIZE,\n",
    "                    bbox[3] * INPUT_SIZE,\n",
    "                    fill=False,\n",
    "                    edgecolor='red',\n",
    "                    linewidth=2\n",
    "                ))\n",
    "                plt.text(\n",
    "                    bbox[0] * INPUT_SIZE,\n",
    "                    bbox[1] * INPUT_SIZE - 5,\n",
    "                    f'Class {class_id}, Conf: {confidence:.2f}',\n",
    "                    bbox=dict(facecolor='red', alpha=0.5),\n",
    "                    fontsize=12,\n",
    "                    color='white'\n",
    "                )\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, true_bboxes, true_class_ids in val_loader:\n",
    "        pred_bboxes, pred_class_logits = model(images)\n",
    "        visualize_predictions(images, pred_bboxes, pred_class_logits)\n",
    "        break  # Visualize only the first batch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
